# Deerhack2025
# Keyo ğŸ—ï¸  
**Voice-Activated Indoor Navigation for the Visually Impaired**

Keyo is an assistive technology project that enables visually impaired individuals to navigate indoor environments using real-time object detection, voice guidance, and natural language interaction.  
The system scans a room via webcam or CCTV, logs object positions, and verbally guides users to requested items like keys â€” all through voice commands.

---

## ğŸš€ Features
- **Voice-Activated Navigation** â€“ Hands-free interaction for ease of use.
- **Real-Time Object Detection** â€“ Detects and tracks objects via OpenCV and MediaPipe.
- **Last Known Location Memory** â€“ Remembers where objects were last seen.
- **Natural Language Interaction** â€“ Users can ask questions like â€œWhere are my keys?â€.
- **Object Description Mode** â€“ Provides verbal descriptions of surroundings on request.

---

## ğŸ› ï¸ Tech Stack
- **Languages:** Python  
- **Libraries & Frameworks:** OpenCV, MediaPipe, Pyttsx3 (Text-to-Speech), SpeechRecognition  
- **Hardware:** Standard webcam or CCTV feed  
- **Platform:** Desktop (Windows/Linux/Mac)  

---

## ğŸ“¸ How It Works
1. **Initialization** â€“ System starts listening for commands.  
2. **Scanning** â€“ Webcam or CCTV scans the environment in real time.  
3. **Detection** â€“ Objects are identified and their positions logged.  
4. **Voice Query** â€“ User asks for an itemâ€™s location.  
5. **Guidance** â€“ System verbally guides the user to the item.  

---

## ğŸ–¥ï¸ Installation & Setup
```bash
# Clone the repository

# Create a virtual environment
python -m venv venv
source venv/bin/activate   # On Windows use: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the application
python main.py
